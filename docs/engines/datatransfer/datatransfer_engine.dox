/*! \page datatransfer_engine DataTransfer Engine

The DataTransfer Engine provides data logging and streaming capabilities to NRP-core.
It enables users to log experiment data to a file for further offline analysis or to stream it over the network for, e.g., remote data visualization and experiment monitoring.

The engine's implementation is based on the \ref engine_grpc "Protobuf over gRPC communication protocol" and thus accepts \ref datapacks_protobuf "Protobuf DataPacks".

In transceiver functions, users can fetch datapacks from other engines, process them, or send them directly to the DataTransfer Engine, where they will be logged or streamed.
Which datapacks are accepted by the engine and how they are processed (i.e., whether they are logged, streamed, or both) is specified in the engine's JSON configuration.
See the \ref engine_datatransfer_config_section "section below" for more details on the engine configuration parameters.

In the simulation configuration file *examples/husky_braitenberg/simulation_config_data_transfer.json*, interested users can find a complete experiment using the DataTransfer Engine.

\section datatransfer_engine_streaming Enabling Data Streaming with MQTT

As mentioned above, besides logging to a file, the DataTransfer Engine also allows streaming datapacks over the network.
For this purpose, the MQTT protocol is used.

To enable data streaming from NRP-core, the Paho MQTT library must be installed as described in \ref installation.
Additionally, the Engine will need to connect to an MQTT broker, and the broker's address must be specified in the engine configuration.

If you need to set up your own MQTT broker, commands are provided below to quickly set one up and run it using Docker.
These commands should be run from the NRP-core source root folder.

\code{.sh}
sudo docker pull eclipse-mosquitto
sudo docker run -it -p 1883:1883 -v ${PWD}/examples/husky_braitenberg/mosquitto.conf:/mosquitto/config/mosquitto.conf eclipse-mosquitto
\endcode

The resulting MQTT broker will listen on port *1883*.
If you wish to use a different port, you can specify it in *examples/husky_braitenberg/mosquitto.conf* or in another mosquitto configuration file.

\section datatransfer_engine_datapacks DataPacks

The DataTransfer Engine processes every incoming datapack and tries to save its "data" field to a file and/or send it to an MQTT broker, depending on the experiment configuration.

\ref datapacks_protobuf "Protobuf DataPacks", containing any protobuf message type, can be sent to the DataTransfer Engine for logging or streaming, with some limitations.
Protobuf message types with *repeated* fields cannot be logged to files but can still be streamed.

Additionally, two Protobuf message types are provided with special formatting support for logging to a file: *Dump.String* and *Dump.ArrayFloat*.
See below for more details.

\subsection dump_proto Dump Protobuf message types

\include dump_msgs.proto

- *Dump.String* has a single field *string_stream* of the string type.
- *Dump.ArrayFloat* can be used to transfer arrays as explained below.

\subsubsection dump_array_float Logging arrays with Dump.ArrayFloat

The *Dump.ArrayFloat* Protobuf message contains two fields:
- float_stream: a repeated float field containing the array data.
- dims: a repeated integer field specifying the dimensions of the array.

The number of elements in the *dims* field specifies the number of dimensions of the array, and the value of each element indicates the number of elements of the array in that dimension.

The DataTransfer engine supports arrays of one or two dimensions.
If *dims* is not set or has one element, the array is treated as 1-dimensional.
If it has two, the array is treated as 2-dimensional.
In this case, the first element indicates the number of rows of the array and the second element the number of columns (*r* and *c* in the explanation below).
The formatting of 3- or more-dimensional arrays is not supported; if *dims* has a number of elements other than 2, then *float_stream* is formatted as a 1-dimensional array.

When the engine is requested to log a *Dump.ArrayFloat* message to a file, *r* lines are printed, each containing *c* elements from *float_stream*.
If the size of *float_stream* is greater than the specified dimensions (i.e., greater than r * c), the excess data (not fitting into the number of rows multiplied by the number of columns) is truncated and not printed.
If the total size of *float_stream* is smaller, then the remaining "space" of the array is printed empty.

Examples of constructing *Dump.ArrayFloat* are given in the file *examples/husky_braitenberg_dump/tf_1.py*.

\subsection logging_address Logging and streaming address

When logging to a file is enabled, datapacks are always logged to a file `<dataDirectory>/<timestamp>/<datapack_name>.data`, where <dataDirectory> is a configuration parameter of the Engine.

When Data Streaming with MQTT is enabled, datapacks are published to an *<MQTTPrefix>/nrp_simulation/<simulationID>/data/<datapack_name>* MQTT topic as serialized protobuf objects. <MQTTPrefix> and <simulationID> are configuration parameters of the Engine.
Whenever the Engine is reset, a message with the text "reset" is published to that topic.

The list of available data topics, along with their corresponding data types, is published to a dedicated topic: *<MQTTPrefix>/nrp_simulation/<simulationID>/data*. The format for this information is provided below:

\code{.json}
[
  {
    "topic": "<MQTTPrefix>/nrp_simulation/<simulationID>/data/<datapack_name1>",
    "type": "<Data.Type1>"
  },
  {
    "topic": "<MQTTPrefix>/nrp_simulation/<simulationID>/data/<datapack_name2>",
    "type": "<Data.Type2>"
  },
  ...
]
\endcode

Upon initialization of the data topic (i.e., before the simulation begins), the `type` value is left blank. It is subsequently updated once the engine determines the data type, which typically occurs when the first message for that topic is sent.

Additionally, a welcome message is published once to the topic *<MQTTPrefix>/nrp_simulation/<simulationID>/welcome*.

\section engine_datatransfer_config_section Engine Configuration Parameters

This Engine type's parameters are defined in the DataTransfer schema (listed \ref engine_datatransfer_schema "here"), which in turn is based on the \ref engine_base_schema "EngineBase" and \ref engine_comm_protocols_schema "EngineGRPC" schemas, inheriting all parameters from them.

To use this engine in an experiment, set `EngineType` to <b>"datatransfer_grpc_engine"</b>.

- Parameters inherited from \ref engine_base_schema "EngineBase" schema:

<table>
<tr><th>Name<th>Description<th>Type<th>Default<th>Required<th>Array
<tr><td>EngineName<td>Name of the engine<td>string<td><td>X<td>
<tr><td>EngineType<td>Engine type. Used by EngineLauncherManager to select the correct engine launcher<td>string<td><td>X<td>
<tr><td>EngineProcCmd<td>Engine Process Launch command<td>string<td><td><td>
<tr><td>EngineProcStartParams<td>Engine Process Start Parameters<td>string<td>[]<td><td>X
<tr><td>EngineEnvParams<td>Engine Process Environment Parameters<td>string<td>[]<td><td>X
<tr><td>EngineLaunchCommand<td>\ref configuration_schema "LaunchCommand" with parameters that will be used to launch the engine process<td>object<td>{"LaunchType":"BasicFork"}<td><td>
<tr><td>EngineTimestep<td>Engine Timestep in seconds<td>number<td>0.01<td><td>
<tr><td>EngineCommandTimeout<td>Engine Timeout (in seconds). It tells how long to wait for the completion of the engine runStep. 0 or negative values are interpreted as no timeout<td>number<td>0.0<td><td>
</table>

- Parameters inherited from the \ref engine_grpc "EngineGRPC" schema:

<table>
<tr><th>Name<th>Description<th>Type<th>Default<th>Required<th>Array
<tr><td>ServerAddress<td>gRPC Server address. Should this address already be in use, simulation initialization will fail<td>string<td>localhost:9004<td><td>
</table>

- Parameters specific to this engine type:

<table>
<tr><th>Name<th>Description<th>Type<th>Default<th>Required<th>Array
<tr><td>MQTTBroker<td>Address of the MQTT broker<td>string<td>localhost:1883<td><td>
<tr><td>dataDirectory<td>Path to the storage of file streams<td>string<td>data<td><td>
<tr><td>MQTTPrefix<td>Prefix to MQTT topics published by this Engine<td>string<td><td><td>
<tr><td>simulationID<td>Simulation identifier to be added to MQTT topics published by this Engine<td>string<td>0<td><td>
<tr><td>streamDataPackMessage<td>If true the engine will stream DataPackMessages, if false it will stream their contained data<td>boolean<td>true<td><td>
<tr><td>dumps<td>List of datapacks for transfer<td>dumpItem<td>[]<td><td>X
</table>

- dumpItem: elements of the *dumps* array above:

<table>
<tr><th>Name<th>Description<th>Type<th>Default<th>Required<th>Array
<tr><td>name<td>Name of the datapack for transfer<td>string<td><td>X<td>
<tr><td>network<td>Trigger, if the datapack should be sent to network<td>boolean<td>false<td><td>
<tr><td>file<td>Trigger, if the datapack should be sent to file<td>boolean<td>false<td><td>
</table>


\section engine_datatransfer_schema Schema

As explained above, the schema used by the DataTransfer engine inherits from the \ref engine_base_schema "EngineBase" and \ref engine_comm_protocols_schema "EngineGRPC" schemas. A complete schema for the configuration of this engine is provided below:

\include engines/engine_datatransfer.json



*/